{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YouTube Comments Spam Classifier",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odudgy5I9Hvk"
      },
      "source": [
        "# YouTube Comments Spam Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEmoHZ-_fjic"
      },
      "source": [
        "Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaR3fO3vaMvv"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import pickle\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "execution_count": 409,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAC0R5pc8cU5",
        "outputId": "eed049ef-5eaf-4290-d8ef-a7201dcfc30f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 410,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy4JR9ATffU4"
      },
      "source": [
        "Import dataset files from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ooTCnz7avT0"
      },
      "source": [
        "z = zipfile.ZipFile(\"/content/drive/MyDrive/YouTube-Spam-Collection-v1.zip\")\n",
        "Psy = pd.read_csv(z.open(\"Youtube01-Psy.csv\"))\n",
        "Katy = pd.read_csv(z.open(\"Youtube02-KatyPerry.csv\"))\n",
        "LMFAO = pd.read_csv(z.open(\"Youtube03-LMFAO.csv\"))\n",
        "Eminem = pd.read_csv(z.open(\"Youtube04-Eminem.csv\"))\n",
        "Shakira = pd.read_csv(z.open(\"Youtube05-Shakira.csv\"))"
      ],
      "execution_count": 411,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "uoLBKbz85m1A",
        "outputId": "1bf6fd1e-4698-42b0-e71c-e6faf7060972"
      },
      "source": [
        "data = pd.concat([Psy, Katy, LMFAO, Eminem, Shakira])\n",
        "data.drop([\"COMMENT_ID\", \"DATE\", \"AUTHOR\"], axis=1, inplace=True)\n",
        "\n",
        "data.shape\n",
        "data.tail(5)"
      ],
      "execution_count": 412,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CONTENT</th>\n",
              "      <th>CLASS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>365</th>\n",
              "      <td>I love this song because we sing it at Camp al...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>I love this song for two reasons: 1.it is abou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>367</th>\n",
              "      <td>wow</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>368</th>\n",
              "      <td>Shakira u are so wiredo</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>369</th>\n",
              "      <td>Shakira is the best dancer</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               CONTENT  CLASS\n",
              "365  I love this song because we sing it at Camp al...      0\n",
              "366  I love this song for two reasons: 1.it is abou...      0\n",
              "367                                                wow      0\n",
              "368                            Shakira u are so wiredo      0\n",
              "369                         Shakira is the best dancer      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 412
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5jrmaMK8vyc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4e6b9b3-6764-4368-92b0-0dcfdf38d8f2"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 413,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1956 entries, 0 to 369\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   CONTENT  1956 non-null   object\n",
            " 1   CLASS    1956 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 45.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im-iQevJf72q"
      },
      "source": [
        "Splitting dataset into train/test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6h45yA5qSa6"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data[\"CONTENT\"], data[\"CLASS\"]) # uses 75% train and 25% test split by default"
      ],
      "execution_count": 414,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbeC_2GE_NED"
      },
      "source": [
        "[NOT CURRENTLY USED] Tokenizing comments in training set (splitting text by word boundaries)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJUYn4dFwQpH"
      },
      "source": [
        "vectorizer = CountVectorizer(lowercase=True)\n",
        "X_train_counts = vectorizer.fit_transform(X_train) # produces a matrix of token counts\n",
        "# print(X_train_counts)\n",
        "# vectorizer.vocabulary_"
      ],
      "execution_count": 415,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuR0kFSJxbnX",
        "outputId": "a4de27ce-67d3-42e8-8c71-c968b5bcbeb1"
      },
      "source": [
        "print(vectorizer.get_stop_words())"
      ],
      "execution_count": 416,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDkaw2RQDTcZ"
      },
      "source": [
        "[NOT CURRENTLY USED] Apply TF-IDF transformation on training set  \n",
        "- more details [here](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html#from-occurrences-to-frequencies)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWOSBOPd9vTP",
        "outputId": "fe5683f5-8e4a-4bcb-fb56-6abb3cb85662"
      },
      "source": [
        "tf_transformer = TfidfTransformer(use_idf=True)\n",
        "X_train_tfidf = tf_transformer.fit_transform(X_train_counts)\n",
        "X_train_tfidf.shape"
      ],
      "execution_count": 417,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1467, 3647)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 417
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYjYt2oZSnWX"
      },
      "source": [
        "Using TfidfVectorizer (equivalent to CountVectorizer followed by TfidfTransformer (e.g. the two steps above))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeWVHRp-SSGV",
        "outputId": "3471144d-c6d0-4a8b-8ae8-58bb7f6e8459"
      },
      "source": [
        "tfidf_vect = TfidfVectorizer(use_idf=True, lowercase=True)\n",
        "X_train_tfidf = tfidf_vect.fit_transform(X_train)\n",
        "X_train_tfidf.shape"
      ],
      "execution_count": 418,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1467, 3647)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 418
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1axu5A7L_S3B"
      },
      "source": [
        "Training the multinomial Naive Bayes model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3M6UjFazsd-",
        "outputId": "d8b9b6ee-c1d8-47cf-b486-5e0d82df10bf"
      },
      "source": [
        "model = MultinomialNB()\n",
        "model.fit(X_train_tfidf, y_train)"
      ],
      "execution_count": 419,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 419
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rr3tI8nk_cCd"
      },
      "source": [
        "Generate predictions on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U97kPKmaDDhH"
      },
      "source": [
        "# perform same feature extraction on test set\n",
        "# X_test_counts = vectorizer.transform(X_test)\n",
        "# X_test_tfidf = tf_transformer.transform(X_test_counts)\n",
        "X_test_tfidf = tfidf_vect.transform(X_test)\n",
        "\n",
        "# make predictions on the test set\n",
        "predictions = model.predict(X_test_tfidf)"
      ],
      "execution_count": 420,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZb3BuLJ_hzL"
      },
      "source": [
        "Generate model performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PZIfWfp5SP-",
        "outputId": "c7a201a0-8fd6-489d-975a-a5dffe99d3d4"
      },
      "source": [
        "confusion_matrix(y_test, predictions)"
      ],
      "execution_count": 421,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[223,  32],\n",
              "       [ 11, 223]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 421
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lULLl_BVEt_w",
        "outputId": "304b6a1c-ba4c-42d1-9e47-0b20c8d167e4"
      },
      "source": [
        "print(classification_report(y_test, predictions))"
      ],
      "execution_count": 422,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.87      0.91       255\n",
            "           1       0.87      0.95      0.91       234\n",
            "\n",
            "    accuracy                           0.91       489\n",
            "   macro avg       0.91      0.91      0.91       489\n",
            "weighted avg       0.92      0.91      0.91       489\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rA-VrptK_6HE",
        "outputId": "1e1cc4e5-aa58-4c10-be43-7b21e7be45e6"
      },
      "source": [
        "model.score(X_test_tfidf, y_test)"
      ],
      "execution_count": 423,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9120654396728016"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 423
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Yw-7vUV5ZVO"
      },
      "source": [
        "Performing cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQOC89GVZm_r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa72cd1e-7915-474a-cf49-7a132e892154"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cv_scores = cross_val_score(loaded_model, X_train_tfidf, y_train, cv=10)\n",
        "print(cv_scores, \"\\n\\nmean: \", cv_scores.mean())\n",
        "\n",
        "# cv example:\n",
        "# https://medium.com/@akshmahesh/detecting-spam-comments-on-youtube-using-machine-learning-948d54f47b3\n",
        "# https://github.com/AkshayLaddha943/Machine-Learning/blob/master/Youtube-Spam-Check/youtube-spam.py"
      ],
      "execution_count": 424,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.91156463 0.93197279 0.95238095 0.91836735 0.93197279 0.85034014\n",
            " 0.95238095 0.93835616 0.89041096 0.93835616] \n",
            "\n",
            "mean:  0.9216102879507968\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-Aq0E9T_l2x"
      },
      "source": [
        "Exporting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-KSnj2JGEFR"
      },
      "source": [
        "# exporting model to pickle file\n",
        "with open(\"model.pkl\", \"wb\") as model_file:\n",
        "  pickle.dump(model, model_file)\n",
        "\n",
        "# Exporting the TF-IDF vectorizer as well\n",
        "# https://stackoverflow.com/questions/29788047/keep-tfidf-result-for-predicting-new-content-using-scikit-for-python\n",
        "with open(\"tfidf-vect.pkl\", \"wb\") as tfidf_vect_file:\n",
        "  pickle.dump(tfidf_vect, tfidf_vect_file)"
      ],
      "execution_count": 425,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNyAaLZy_n-Q"
      },
      "source": [
        ""
      ],
      "execution_count": 425,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itzMQYQ9_n5i"
      },
      "source": [
        "### Testing the model with custom comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMgxOgDrCU1j"
      },
      "source": [
        "# loading the model\n",
        "with open(\"model.pkl\", \"rb\") as model_file:\n",
        "  loaded_model = pickle.load(model_file)\n",
        "loaded_model\n",
        "\n",
        "# loading the tfidf vectorizer\n",
        "with open(\"tfidf-vect.pkl\", \"rb\") as tfidf_vect_file:\n",
        "  transformer = pickle.load(tfidf_vect_file)"
      ],
      "execution_count": 426,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJjWHQ_PDWG3",
        "outputId": "5b1f179a-7876-4500-a094-f2be2880b6ef"
      },
      "source": [
        "# testing the model with our own test comments\n",
        "comments = np.array([['check out facebook.com'], ['this was a really helpful video!'], [\"i am not spam\"]])\n",
        "test_df = pd.DataFrame(data=comments, columns=['CONTENT'])\n",
        "test_df\n",
        "\n",
        "test_comm_tfidf = transformer.transform(test_df['CONTENT'])\n",
        "# print(transformer.get_feature_names())\n",
        "\n",
        "loaded_model.predict(test_comm_tfidf)"
      ],
      "execution_count": 427,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 427
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vqZ1sUzOs4b"
      },
      "source": [
        ""
      ],
      "execution_count": 427,
      "outputs": []
    }
  ]
}
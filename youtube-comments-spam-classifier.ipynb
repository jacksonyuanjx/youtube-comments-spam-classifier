{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YouTube Comments Spam Classifier",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odudgy5I9Hvk"
      },
      "source": [
        "# YouTube Comments Spam Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEmoHZ-_fjic"
      },
      "source": [
        "### Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaR3fO3vaMvv"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import pickle\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAC0R5pc8cU5",
        "outputId": "dd29ded2-b3fa-43cc-f857-1eef3f0fef81"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy4JR9ATffU4"
      },
      "source": [
        "### Import dataset files from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ooTCnz7avT0"
      },
      "source": [
        "z = zipfile.ZipFile(\"/content/drive/MyDrive/YouTube-Spam-Collection-v1.zip\")\n",
        "Psy = pd.read_csv(z.open(\"Youtube01-Psy.csv\"))\n",
        "Katy = pd.read_csv(z.open(\"Youtube02-KatyPerry.csv\"))\n",
        "LMFAO = pd.read_csv(z.open(\"Youtube03-LMFAO.csv\"))\n",
        "Eminem = pd.read_csv(z.open(\"Youtube04-Eminem.csv\"))\n",
        "Shakira = pd.read_csv(z.open(\"Youtube05-Shakira.csv\"))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "uoLBKbz85m1A",
        "outputId": "4eaf28cb-63c7-4da0-fc3f-5e984b40c6b7"
      },
      "source": [
        "data = pd.concat([Psy, Katy, LMFAO, Eminem, Shakira])\n",
        "data.drop([\"COMMENT_ID\", \"DATE\", \"AUTHOR\"], axis=1, inplace=True)\n",
        "\n",
        "data.shape\n",
        "data.tail(5)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CONTENT</th>\n",
              "      <th>CLASS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>365</th>\n",
              "      <td>I love this song because we sing it at Camp al...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>I love this song for two reasons: 1.it is abou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>367</th>\n",
              "      <td>wow</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>368</th>\n",
              "      <td>Shakira u are so wiredo</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>369</th>\n",
              "      <td>Shakira is the best dancer</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               CONTENT  CLASS\n",
              "365  I love this song because we sing it at Camp al...      0\n",
              "366  I love this song for two reasons: 1.it is abou...      0\n",
              "367                                                wow      0\n",
              "368                            Shakira u are so wiredo      0\n",
              "369                         Shakira is the best dancer      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5jrmaMK8vyc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "316e8c46-35fe-48c7-e996-1499d2f35e70"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1956 entries, 0 to 369\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   CONTENT  1956 non-null   object\n",
            " 1   CLASS    1956 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 45.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im-iQevJf72q"
      },
      "source": [
        "### Splitting dataset into train/test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6h45yA5qSa6"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data[\"CONTENT\"], data[\"CLASS\"]) # uses 75% train and 25% test split by default"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3NbUPWZb_aj"
      },
      "source": [
        "### Tokenizing comments in training set and applying TF-IDF vectorizer on training set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbeC_2GE_NED"
      },
      "source": [
        "#### [NOT CURRENTLY USED] Tokenizing comments in training set (splitting text by word boundaries)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJUYn4dFwQpH"
      },
      "source": [
        "vectorizer = CountVectorizer(lowercase=True)\n",
        "X_train_counts = vectorizer.fit_transform(X_train) # produces a matrix of token counts\n",
        "# print(X_train_counts)\n",
        "# vectorizer.vocabulary_"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuR0kFSJxbnX",
        "outputId": "df27e84e-0fe6-4e32-e72f-6e1dea1e8153"
      },
      "source": [
        "print(vectorizer.get_stop_words())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDkaw2RQDTcZ"
      },
      "source": [
        "#### [NOT CURRENTLY USED] Apply TF-IDF transformation on training set  \n",
        "- more details [here](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html#from-occurrences-to-frequencies)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWOSBOPd9vTP",
        "outputId": "926d0a11-def9-4cd0-ed5c-bbc47e80ee41"
      },
      "source": [
        "tf_transformer = TfidfTransformer(use_idf=True)\n",
        "X_train_tfidf = tf_transformer.fit_transform(X_train_counts)\n",
        "X_train_tfidf.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1467, 3694)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYjYt2oZSnWX"
      },
      "source": [
        "#### Using TfidfVectorizer (equivalent to CountVectorizer followed by TfidfTransformer (e.g. the two steps above))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeWVHRp-SSGV",
        "outputId": "4774a00c-8924-44ea-f7a6-4e564f642052"
      },
      "source": [
        "tfidf_vect = TfidfVectorizer(use_idf=True, lowercase=True)\n",
        "X_train_tfidf = tfidf_vect.fit_transform(X_train)\n",
        "X_train_tfidf.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1467, 3694)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1axu5A7L_S3B"
      },
      "source": [
        "### Training the multinomial Naive Bayes model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3M6UjFazsd-",
        "outputId": "0799ff56-dee5-4d36-b594-33130b798cfd"
      },
      "source": [
        "model = MultinomialNB()\n",
        "model.fit(X_train_tfidf, y_train)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rr3tI8nk_cCd"
      },
      "source": [
        "### Generate predictions on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U97kPKmaDDhH"
      },
      "source": [
        "# perform same feature extraction on test set\n",
        "# X_test_counts = vectorizer.transform(X_test)\n",
        "# X_test_tfidf = tf_transformer.transform(X_test_counts)\n",
        "X_test_tfidf = tfidf_vect.transform(X_test)\n",
        "\n",
        "# make predictions on the test set\n",
        "predictions = model.predict(X_test_tfidf)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZb3BuLJ_hzL"
      },
      "source": [
        "### Generate model performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PZIfWfp5SP-",
        "outputId": "0407813d-0092-4994-8ba8-4600a73c6055"
      },
      "source": [
        "confusion_matrix(y_test, predictions)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[205,  33],\n",
              "       [  9, 242]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lULLl_BVEt_w",
        "outputId": "fac0281d-a92d-488e-f731-39a4fcbd0405"
      },
      "source": [
        "print(classification_report(y_test, predictions))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.86      0.91       238\n",
            "           1       0.88      0.96      0.92       251\n",
            "\n",
            "    accuracy                           0.91       489\n",
            "   macro avg       0.92      0.91      0.91       489\n",
            "weighted avg       0.92      0.91      0.91       489\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rA-VrptK_6HE",
        "outputId": "f6bfb3d9-3d9e-4e95-ac6a-0a3bf73a7597"
      },
      "source": [
        "model.score(X_test_tfidf, y_test)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9141104294478528"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Yw-7vUV5ZVO"
      },
      "source": [
        "### Performing cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQOC89GVZm_r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aa5aa24-2450-4b0e-9987-1b2097425912"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cv_scores = cross_val_score(model, X_train_tfidf, y_train, cv=10)\n",
        "print(cv_scores, \"\\n\\nmean: \", cv_scores.mean())\n",
        "\n",
        "# cv example:\n",
        "# https://medium.com/@akshmahesh/detecting-spam-comments-on-youtube-using-machine-learning-948d54f47b3\n",
        "# https://github.com/AkshayLaddha943/Machine-Learning/blob/master/Youtube-Spam-Check/youtube-spam.py"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.91836735 0.94557823 0.91836735 0.91156463 0.91156463 0.93877551\n",
            " 0.93197279 0.94520548 0.93150685 0.91780822] \n",
            "\n",
            "mean:  0.9270711024135683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-Aq0E9T_l2x"
      },
      "source": [
        "### Exporting the model and TF-IDF vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-KSnj2JGEFR"
      },
      "source": [
        "# exporting model to pickle file\n",
        "with open(\"model.pkl\", \"wb\") as model_file:\n",
        "  pickle.dump(model, model_file)\n",
        "\n",
        "# exporting the TF-IDF vectorizer as well\n",
        "# https://stackoverflow.com/questions/29788047/keep-tfidf-result-for-predicting-new-content-using-scikit-for-python\n",
        "with open(\"tfidf-vect.pkl\", \"wb\") as tfidf_vect_file:\n",
        "  pickle.dump(tfidf_vect, tfidf_vect_file)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNyAaLZy_n-Q"
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itzMQYQ9_n5i"
      },
      "source": [
        "### Testing the model with custom comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMgxOgDrCU1j"
      },
      "source": [
        "# loading the model\n",
        "with open(\"model.pkl\", \"rb\") as model_file:\n",
        "  loaded_model = pickle.load(model_file)\n",
        "loaded_model\n",
        "\n",
        "# loading the tfidf vectorizer\n",
        "with open(\"tfidf-vect.pkl\", \"rb\") as tfidf_vect_file:\n",
        "  loaded_vectorizer = pickle.load(tfidf_vect_file)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJjWHQ_PDWG3",
        "outputId": "75e7fbd5-9bc8-487a-ddb6-4a62f990c4ff"
      },
      "source": [
        "# testing the model with our own test comments\n",
        "comments = np.array([['check out facebook.com'], ['this was a really helpful video!'], [\"i am not spam\"]])\n",
        "test_df = pd.DataFrame(data=comments, columns=['CONTENT'])\n",
        "test_df\n",
        "\n",
        "test_comm_tfidf = loaded_vectorizer.transform(test_df['CONTENT'])\n",
        "# print(loaded_vectorizer.get_feature_names())\n",
        "\n",
        "loaded_model.predict(test_comm_tfidf)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vqZ1sUzOs4b"
      },
      "source": [
        ""
      ],
      "execution_count": 36,
      "outputs": []
    }
  ]
}